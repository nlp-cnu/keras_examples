
BioBERT:
1) download biobert v1.1 (+Pubmed 1M) from https://github.com/dmis-lab/biobert

   or directly from this link:
   https://drive.google.com/file/d/1R84voFKHfWV9xjzeLzWBbmY1uOMYpnyD/view?usp=sharing

2) convert it by running the following command in the extracted folder
   transformers-cli convert --model_type bert  --tf_checkpoint=./model.ckpt-1000000   --config=./bert_config.json   --pytorch_dump_output=./pytorch_model.bin

3) rename the config file: mv bert_config.json config.json 




BlueBERT PubMed:
1) download from https://github.com/ncbi-nlp/bluebert BlueBERT-Base, Uncased, PubMed

   or directly from: https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/NCBI-BERT/NCBI_BERT_pubmed_uncased_L-12_H-768_A-12.zip

2) Convert it by running the following command in the extracted folder:
transformers-cli convert --model_type bert  --tf_checkpoint=./bert_model.ckpt   --config=./bert_config.json   --pytorch_dump_output=./pytorch_model.bin

3) rename the config file: mv bert_config.json config.json

4) add the following line to the config files:   "model_type": "bert",  




BlueBERT PubMed + Mimic:
1) download from https://github.com/ncbi-nlp/bluebert BlueBERT-Base, Uncased, PubMed+MIMIC-III

  or directly from: https://ftp.ncbi.nlm.nih.gov/pub/lu/Suppl/NCBI-BERT/NCBI_BERT_pubmed_mimic_uncased_L-12_H-768_A-12.zip


2) Convert it by running the following command in the extracted folder:
transformers-cli convert --model_type bert  --tf_checkpoint=./bert_model.ckpt  --config=./bert_config.json   --pytorch_dump_output=./pytorch_model.bin

3) rename the config file: mv bert_config.json config.json 

4) add the following line to the config files:   "model_type": "bert",



BioClinicalBERT, Bio+Discharge Summary BERT, Clinical BERT, Discharge Summary BERT
1) download from https://github.com/EmilyAlsentzer/clinicalBERT

  or directly from: https://www.dropbox.com/s/8armk04fu16algz/pretrained_bert_tf.tar.gz?dl=0

2) no conversion is necessary
3) rename the config file: mv bert_config.json config.json 
